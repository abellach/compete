M$status2[(n-nbig2+1):n] <- 0
M$kmc[(n-nbig2+1):n] <- M$kmc[n-nbig2]
}
#head(M)
# Summarize event types
n <- length(M[,1])
num1 <- sum(M$status1)
num2 <- sum(M$status2)
numc <- sum(M$status0)
#
# take subsets
M1 <- subset(M, status == 1)
M02 <- subset(M, status != 1)
M2 <- subset(M02, status == 2)
Mc <- subset(M02, status == 0)
#
# Covariate matrices
cova <- as.matrix(M[ , !(names(M) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
cov1 <- as.matrix(M1[ , !(names(M1) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
cov2 <- as.matrix(M2[ , !(names(M2) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
covc <- as.matrix(Mc[ , !(names(Mc) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
cov02 <- as.matrix(M02[ , !(names(M02) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
numcov <- length(cova[1,])
#
# calculate FG weights
w.new<-matrix(rep(0,num2*num1),nrow=num2)
for (i in 1:num2){w.new[i,]<-(M1$ind>M2$ind[i])*(M1$kmc/M2$kmc[i])}
#
Mall <- lower.tri(matrix(rep(1,n*n),nrow = n), diag = TRUE)*1
M3 <- Mall[M1$ind,M1$ind]
M4 <- Mall[,M1$ind]
M5 <- Mall[Mc$ind,M1$ind]
M6 <- Mall[M2$ind,M1$ind]
#
# Objective function for optimization
fn <- function(x){
beta <- x[1:numcov]
alpha <- x[(numcov+1):(numcov+num1)]
lambda <- exp(alpha)
#
Lam.all<-rowSums(M4%*%lambda)
Lamb<-t(matrix(rep(lambda,num2),nrow=num1))
V5 <- matrix(rep(exp(cov2%*%beta),num1),nrow=num2)
#
f1 <- sum(log(lambda))
f2 <- sum(cov1%*%beta)
f4 <- sum(exp(cova%*%beta)*Lam.all)
f5 <- sum(w.new*V5*Lamb)
#
f<- -f1-f2+f4+f5
return(f)
}
# Initial values
#compr <- sapply(1:num1, function(j) sum(M$status2[M1$ind[max(1, j - 1)]:M1$ind[j]]) / M$kmc[M1$ind[j]])
#typ2 <- (M3 %*% compr) * M1$kmc
#salpha <- log(1 / ((n - M1$ind) + typ2))
salpha <- rep(1/n,num1)
par <- c(rep(0, numcov), salpha)
# Optimization
result <- optim(par,fn=fn,gr=NULL,method="BFGS")
estpar <- c(result$par[1:numcov],exp(result$par[(numcov+1):(numcov+num1)]))
beta <- estpar[1:numcov]
lambda <- estpar[-(1:numcov)]
Lambda <- M3 %*% lambda
#
t1<-sum(ifelse(M1$time<=tau,1,0))
t4<-sum(ifelse(M1$time<=tau/4,1,0))
t2<-sum(ifelse(M1$time<=tau/2,1,0))
#
latau <- c(sum(lambda[1:t4]), sum(lambda[1:t2]), sum(lambda[1:t1]))
para <- round(c(beta, latau), 5)
# Variance estimation: first calculation for the Hessian
fback <- function(x){
beta <- x[1:numcov]
lambda <- x[(numcov+1):(numcov+num1)]
#
Lam.all<-rowSums(M4%*%lambda)
Lamb<-t(matrix(rep(lambda,num2),nrow=num1))
V5 <- matrix(rep(exp(cov2%*%beta),num1),nrow=num2)
#
f1 <- sum(log(lambda))
f2 <- sum(cov1%*%beta)
f4 <- sum(exp(cova%*%beta)*Lam.all)
f5 <- sum(w.new*V5*Lamb)
#
fback<- -f1-f2+f4+f5
return(fback)
}
# caclHessian
Mhe <- numDeriv::hessian(func=fback, x=estpar)
# inverse Fisher information (breadi)
# not using solve(Mhe)
# do this instead utilizing Cholesky factorization
MatrixL <- chol(Mhe)
breadi.new <- chol2inv(MatrixL)
# Matrix that transforms vector of jump sizes to vector of cumulative jump sizes
Mtrafo<-rbind(cbind(diag(numcov),matrix(rep(0,numcov*num1),nrow=numcov)),cbind(matrix(rep(0,num1*numcov),nrow=num1),M3))
breadinv<-Mtrafo%*%breadi%*%t(Mtrafo)
breadr<-round(sqrt(diag(breadinv)),5)
var.bread<-c(breadr[1:numcov],breadr[t4+numcov],breadr[t2+numcov],breadr[t1+numcov])
# sandwich estimator
grad<-array(0,dim=c(numcov+num1,numcov+num1,n))
gradi<-array(0,c(n,numcov+num1))
lambda<-estpar[(numcov+1):(numcov+num1)]
beta<-estpar[1:numcov]
Lambda<-M3%*%lambda
Lamc<-rowSums(M5%*%lambda)
Lam2<-rowSums(M6%*%lambda)
vecii<-c(1:num1)
#
# individuals with events of type 1
for(k in 1:numcov){gradi[M1$ind,k]<-(-1)*cov1[,k]*(1-exp(cov1%*%beta)*Lambda)}
for(k in 1:num1){gradi[M1$ind,numcov+k]<-(-1)*((vecii==k)/lambda[k]-(k<=vecii)*exp(cov1%*%beta))}
# censored individuals
for(k in 1:numcov){gradi[Mc$ind,k]<-covc[,k]*exp(covc%*%beta)*Lamc}
for(k in 1:num1){gradi[Mc$ind,numcov+k]<-(M1$ind[k]<=Mc$ind)*exp(covc%*%beta)}
#
# individuals with events of type 2
Mglami<-t(matrix(rep(lambda,num2),nrow=num1))
for(l in 1:numcov){gradi[M2$ind,l]<-cov2[,l]*exp(cov2%*%beta)*Lam2+cov2[,l]*exp(cov2%*%beta)*rowSums(w.new*Mglami)}
for(l in 1:(num1-1)){gradi[M2$ind,(numcov+l)]<-(M1$ind[l]<=M2$ind)*exp(cov2%*%beta)+rowSums(exp(cov2%*%beta)*w.new[,l])}
gradi[M2$ind,(numcov+num1)]<-(M1$ind[num1]<=M2$ind)*exp(cov2%*%beta)+rowSums(exp(cov2%*%beta)*w.new[,num1])
#
for(i in 1:n){grad[,,i]<-(gradi[i,])%*%t(gradi[i,])}
#
# comupute sandwich estimator
meat<-apply(grad,1:2,sum)
sandw <- (Mtrafo)%*%(breadi)%*%(meat)%*%t(breadi)%*%t(Mtrafo)
sandwich<-round(sqrt(diag(sandw)),5)
var.sand<-c(sandwich[1:numcov],sandwich[t4+numcov],sandwich[t2+numcov],sandwich[t1+numcov])
#
# sandwich including correction term
Mus1<-matrix(rep(0,n*n),nrow=n)
diag(Mus1)<-M$status0
head(M)
#
hazn<-(M$status==0)/(n-M$ind+1)
Mus2<-matrix(rep(0,n*n),nrow=n)
for (i in 1:n){Mus2[i,]<-hazn*(M$ind[i]>=M$ind)}
#
Mu<-Mus1-Mus2
# estimates for the hazard, beta and cumulative hazard
MLam<-t(matrix(rep(Lambda,num2),nrow=num1))
Mlam<-t(matrix(rep(lambda,num2),nrow=num1))
Mlamn<-t(matrix(rep(lambda,n),nrow=n))
Mzbet<-matrix(rep(exp(cov2%*%beta),num1),nrow=num2)
Mzbetn<-t(matrix(rep(exp(cov2%*%beta),n),nrow=n))
# Define Matrix e^{beta^TZ_j}A(X_k)=Mzbet[]
MzbL<-Mzbet*MLam
# Define first part of residual term, for beta
Mjk<-w.new*Mlam
Muk.ind<-array(0,dim=c(n,num1))
for(u in 1:n){Muk.ind[u,]<-(u<=M1$ind)}
Mju<-array(0,dim=c(num2,n))
for(j in 1:num2){for(u in 1:n){Mju[j,u]<-sum(Mjk[j,]*Muk.ind[u,])}}
Mju.ind<-array(0,dim=c(num2,n))
for(u in 1:n){Mju.ind[,u]<-(M2$ind<=u)}
Mju.new<-Mju*Mju.ind*Mzbetn
#
q1<-array(0,dim=c(numcov,n))
for(l in 1:numcov){for(u in 1:n){q1[l,u]<-sum(cov2[,l]*Mju.new[,u])}}
#
#second part of residuals for baseline
M2jl<-w.new*Mzbet
M2jl.ind<-Mju.ind
M2lu.ind<-t(Muk.ind)
M2lu<-array(0,dim=c(num1,n))
for(l in 1:num1){for(u in 1:n){M2lu[l,u]<-sum(M2jl[,l]*M2jl.ind[,u])}}
#
q2<-M2lu.ind*M2lu
q<-rbind(q1,q2)
# define pi(u)
pi<-n-M$ind+1
psi<-array(0,dim=c(n,num1+numcov))
for(k in 1:(num1+numcov)){for(i in 1:n){psi[i,k]<-sum((q[k,]/pi)*Mu[i,])}}
#
grad3<-array(0,dim=c(numcov+num1,numcov+num1,n))
for (i in 1:n){grad3[,,i]<-(gradi[i,]+psi[i,])%*%t(gradi[i,]+psi[i,])}
#
# adjusted sandwich
meat3 <- apply(grad3,1:2,sum)
sandw3<-(Mtrafo)%*%(breadi)%*%(meat3)%*%(breadi)%*%t(Mtrafo)
sandwich3<-round(sqrt(diag(sandw3)),5)
var.sand3<-c(sandwich3[1:numcov],sandwich3[t4+numcov],sandwich3[t2+numcov],sandwich3[t1+numcov])
#print(c(vsta,vnum,nall))
sum(mydata$time==tau)
#
result1 <- c(para,var.bread,var.sand,var.sand3)
para <- result1[1:5]
varbread <- result1[6:10]
varsand <- result1[11:15]
varsand3 <- result1[16:20]
#################################################################################
return(data.frame(cbind(para,varbread,varsand,varsand3)))
}
#wNPMLE.BC(mydata,1,0.95)
#install.packages("roxygen2")
#library(roxygen2)
#devtools::load_all()
#devtools::document()
#roxygen2::roxygenise()
#rm(list = c("wNPMLE.BC"))
#devtools::check()
wNPMLE.BC(mydata,1,0.95)
devtools::check()
devtools::check()
#wNPMLE.BC(mydata,1,0.95)
#install.packages("roxygen2")
#library(roxygen2)
#devtools::load_all()
#devtools::document()
#roxygen2::roxygenise()
#rm(list = c("wNPMLE.BC"))
#devtools::check()
rm(list = c("wNPMLE.BC"))
devtools::document()
roxygen2::roxygenise()
"))
#
devtools::check()
)
)
)
)
)
)
)
)
)
)
))
}
file.rename(
from = "wNPMLE.BC.R",       # path to current file location (likely package root)
to = file.path("R", "wNPMLE.BC.R")  # move into R/ folder
)
setwd("C:/Users/abell/OneDrive/Documents/compete")
file.rename(
from = "wNPMLE.BC.R",       # path to current file location (likely package root)
to = file.path("R", "wNPMLE.BC.R")  # move into R/ folder
)
file.rename(
from = "C:/Users/abell/Documents/compete/wNPMLE.BC.R",
to = "C:/Users/abell/Documents/compete/R/wNPMLE.BC.R"
)
file.rename(
from = "~/abell/Documents/compete/wNPMLE.BC.R",
to = "~/Documents/compete/R/wNPMLE.BC.R"
)
#' @param mydata matrix with columns=(time,status,covariates)
#' @param rho Box-Cox transformation parameter
#' @param tau endpoint of study
#' @return returns a matrix with columns=parameters,Fisher inverse,
#' simple sandwich estimator,corrected sandwich estimator
#' @export
#' @importFrom stats optim
#' @importFrom utils head
wNPMLE.BC <- function(mydata,rho,tau)
{
#
utils::globalVariables(c("status", "breadi"))
#
order.time <- order(mydata$time)
Ma <- mydata[order.time, ]
rownames(Ma) <- NULL
# Kaplan-Meier estimator of censoring distribution
kmc <- cumprod(1 - (Ma$status == 0) / rev(seq_len(n)))
ind <- 1:n
M <- data.frame(Ma, kmc = kmc, ind = ind)
M$status0 <- 1*(M$status==0)
M$status1 <- 1*(M$status==1)
M$status2 <- 1*(M$status==2)
# head(M)
# Handle small values of the KM estimator
smallkmc <- ifelse(M$kmc<.05,1,0)
n.smallkmc <- sum(smallkmc)
#
if(n.smallkmc>0){
v.salt <- as.vector(seq(tau+1e-5,(tau+n.smallkmc*1e-5),by=1e-5))
M$time[(n-n.smallkmc+1):n]< - v.salt
M$status[(n-n.smallkmc+1):n] <- 0
M$status0[(n-n.smallkmc+1):n] <- 1
M$status1[(n-n.smallkmc+1):n] <- 0
M$status2[(n-n.smallkmc+1):n] <- 0
M$kmc[(n-n.smallkmc+1):n]=M$kmc[n-n.smallkmc]
}
#
numbig2<-ifelse(M$time>tau,1,0)
nbig2<-sum(numbig2)
#
if(nbig2>0){
v.salt2<-as.vector(seq(tau+1e-5,(tau+nbig2*1e-5),by=1e-5))
M$time[(n-nbig2+1):n]<-v.salt2
M$status[(n-nbig2+1):n] <- 0
M$status0[(n-nbig2+1):n] <- 1
M$status1[(n-nbig2+1):n] <- 0
M$status2[(n-nbig2+1):n] <- 0
M$kmc[(n-nbig2+1):n] <- M$kmc[n-nbig2]
}
#head(M)
# Summarize event types
n <- length(M[,1])
num1 <- sum(M$status1)
num2 <- sum(M$status2)
numc <- sum(M$status0)
#
# take subsets
M1 <- subset(M, status == 1)
M02 <- subset(M, status != 1)
M2 <- subset(M02, status == 2)
Mc <- subset(M02, status == 0)
#
# Covariate matrices
cova <- as.matrix(M[ , !(names(M) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
cov1 <- as.matrix(M1[ , !(names(M1) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
cov2 <- as.matrix(M2[ , !(names(M2) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
covc <- as.matrix(Mc[ , !(names(Mc) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
cov02 <- as.matrix(M02[ , !(names(M02) %in% c("time", "status","status0",
"status1","status2","kmc","ind"))])
numcov <- length(cova[1,])
#
# calculate FG weights
w.new<-matrix(rep(0,num2*num1),nrow=num2)
for (i in 1:num2){w.new[i,]<-(M1$ind>M2$ind[i])*(M1$kmc/M2$kmc[i])}
#
Mall <- lower.tri(matrix(rep(1,n*n),nrow = n), diag = TRUE)*1
M3 <- Mall[M1$ind,M1$ind]
M4 <- Mall[,M1$ind]
M5 <- Mall[Mc$ind,M1$ind]
M6 <- Mall[M2$ind,M1$ind]
#
# Objective function for optimization
fn <- function(x){
beta <- x[1:numcov]
alpha <- x[(numcov+1):(numcov+num1)]
lambda <- exp(alpha)
#
Lam.all<-rowSums(M4%*%lambda)
Lamb<-t(matrix(rep(lambda,num2),nrow=num1))
V5 <- matrix(rep(exp(cov2%*%beta),num1),nrow=num2)
#
f1 <- sum(log(lambda))
f2 <- sum(cov1%*%beta)
f4 <- sum(exp(cova%*%beta)*Lam.all)
f5 <- sum(w.new*V5*Lamb)
#
f<- -f1-f2+f4+f5
return(f)
}
# Initial values
#compr <- sapply(1:num1, function(j) sum(M$status2[M1$ind[max(1, j - 1)]:M1$ind[j]]) / M$kmc[M1$ind[j]])
#typ2 <- (M3 %*% compr) * M1$kmc
#salpha <- log(1 / ((n - M1$ind) + typ2))
salpha <- rep(1/n,num1)
par <- c(rep(0, numcov), salpha)
# Optimization
result <- optim(par,fn=fn,gr=NULL,method="BFGS")
estpar <- c(result$par[1:numcov],exp(result$par[(numcov+1):(numcov+num1)]))
beta <- estpar[1:numcov]
lambda <- estpar[-(1:numcov)]
Lambda <- M3 %*% lambda
#
t1<-sum(ifelse(M1$time<=tau,1,0))
t4<-sum(ifelse(M1$time<=tau/4,1,0))
t2<-sum(ifelse(M1$time<=tau/2,1,0))
#
latau <- c(sum(lambda[1:t4]), sum(lambda[1:t2]), sum(lambda[1:t1]))
para <- round(c(beta, latau), 5)
# Variance estimation: first calculation for the Hessian
fback <- function(x){
beta <- x[1:numcov]
lambda <- x[(numcov+1):(numcov+num1)]
#
Lam.all<-rowSums(M4%*%lambda)
Lamb<-t(matrix(rep(lambda,num2),nrow=num1))
V5 <- matrix(rep(exp(cov2%*%beta),num1),nrow=num2)
#
f1 <- sum(log(lambda))
f2 <- sum(cov1%*%beta)
f4 <- sum(exp(cova%*%beta)*Lam.all)
f5 <- sum(w.new*V5*Lamb)
#
fback<- -f1-f2+f4+f5
return(fback)
}
# caclHessian
Mhe <- numDeriv::hessian(func=fback, x=estpar)
# inverse Fisher information (breadi)
# not using solve(Mhe)
# do this instead utilizing Cholesky factorization
MatrixL <- chol(Mhe)
breadi.new <- chol2inv(MatrixL)
# Matrix that transforms vector of jump sizes to vector of cumulative jump sizes
Mtrafo<-rbind(cbind(diag(numcov),matrix(rep(0,numcov*num1),nrow=numcov)),cbind(matrix(rep(0,num1*numcov),nrow=num1),M3))
breadinv<-Mtrafo%*%breadi%*%t(Mtrafo)
breadr<-round(sqrt(diag(breadinv)),5)
var.bread<-c(breadr[1:numcov],breadr[t4+numcov],breadr[t2+numcov],breadr[t1+numcov])
# sandwich estimator
grad<-array(0,dim=c(numcov+num1,numcov+num1,n))
gradi<-array(0,c(n,numcov+num1))
lambda<-estpar[(numcov+1):(numcov+num1)]
beta<-estpar[1:numcov]
Lambda<-M3%*%lambda
Lamc<-rowSums(M5%*%lambda)
Lam2<-rowSums(M6%*%lambda)
vecii<-c(1:num1)
#
# individuals with events of type 1
for(k in 1:numcov){gradi[M1$ind,k]<-(-1)*cov1[,k]*(1-exp(cov1%*%beta)*Lambda)}
for(k in 1:num1){gradi[M1$ind,numcov+k]<-(-1)*((vecii==k)/lambda[k]-(k<=vecii)*exp(cov1%*%beta))}
# censored individuals
for(k in 1:numcov){gradi[Mc$ind,k]<-covc[,k]*exp(covc%*%beta)*Lamc}
for(k in 1:num1){gradi[Mc$ind,numcov+k]<-(M1$ind[k]<=Mc$ind)*exp(covc%*%beta)}
#
# individuals with events of type 2
Mglami<-t(matrix(rep(lambda,num2),nrow=num1))
for(l in 1:numcov){gradi[M2$ind,l]<-cov2[,l]*exp(cov2%*%beta)*Lam2+cov2[,l]*exp(cov2%*%beta)*rowSums(w.new*Mglami)}
for(l in 1:(num1-1)){gradi[M2$ind,(numcov+l)]<-(M1$ind[l]<=M2$ind)*exp(cov2%*%beta)+rowSums(exp(cov2%*%beta)*w.new[,l])}
gradi[M2$ind,(numcov+num1)]<-(M1$ind[num1]<=M2$ind)*exp(cov2%*%beta)+rowSums(exp(cov2%*%beta)*w.new[,num1])
#
for(i in 1:n){grad[,,i]<-(gradi[i,])%*%t(gradi[i,])}
#
# comupute sandwich estimator
meat<-apply(grad,1:2,sum)
sandw <- (Mtrafo)%*%(breadi)%*%(meat)%*%t(breadi)%*%t(Mtrafo)
sandwich<-round(sqrt(diag(sandw)),5)
var.sand<-c(sandwich[1:numcov],sandwich[t4+numcov],sandwich[t2+numcov],sandwich[t1+numcov])
#
# sandwich including correction term
Mus1<-matrix(rep(0,n*n),nrow=n)
diag(Mus1)<-M$status0
head(M)
#
hazn<-(M$status==0)/(n-M$ind+1)
Mus2<-matrix(rep(0,n*n),nrow=n)
for (i in 1:n){Mus2[i,]<-hazn*(M$ind[i]>=M$ind)}
#
Mu<-Mus1-Mus2
# estimates for the hazard, beta and cumulative hazard
MLam<-t(matrix(rep(Lambda,num2),nrow=num1))
Mlam<-t(matrix(rep(lambda,num2),nrow=num1))
Mlamn<-t(matrix(rep(lambda,n),nrow=n))
Mzbet<-matrix(rep(exp(cov2%*%beta),num1),nrow=num2)
Mzbetn<-t(matrix(rep(exp(cov2%*%beta),n),nrow=n))
# Define Matrix e^{beta^TZ_j}A(X_k)=Mzbet[]
MzbL<-Mzbet*MLam
# Define first part of residual term, for beta
Mjk<-w.new*Mlam
Muk.ind<-array(0,dim=c(n,num1))
for(u in 1:n){Muk.ind[u,]<-(u<=M1$ind)}
Mju<-array(0,dim=c(num2,n))
for(j in 1:num2){for(u in 1:n){Mju[j,u]<-sum(Mjk[j,]*Muk.ind[u,])}}
Mju.ind<-array(0,dim=c(num2,n))
for(u in 1:n){Mju.ind[,u]<-(M2$ind<=u)}
Mju.new<-Mju*Mju.ind*Mzbetn
#
q1<-array(0,dim=c(numcov,n))
for(l in 1:numcov){for(u in 1:n){q1[l,u]<-sum(cov2[,l]*Mju.new[,u])}}
#
#second part of residuals for baseline
M2jl<-w.new*Mzbet
M2jl.ind<-Mju.ind
M2lu.ind<-t(Muk.ind)
M2lu<-array(0,dim=c(num1,n))
for(l in 1:num1){for(u in 1:n){M2lu[l,u]<-sum(M2jl[,l]*M2jl.ind[,u])}}
#
q2<-M2lu.ind*M2lu
q<-rbind(q1,q2)
# define pi(u)
pi<-n-M$ind+1
psi<-array(0,dim=c(n,num1+numcov))
for(k in 1:(num1+numcov)){for(i in 1:n){psi[i,k]<-sum((q[k,]/pi)*Mu[i,])}}
#
grad3<-array(0,dim=c(numcov+num1,numcov+num1,n))
for (i in 1:n){grad3[,,i]<-(gradi[i,]+psi[i,])%*%t(gradi[i,]+psi[i,])}
#
# adjusted sandwich
meat3 <- apply(grad3,1:2,sum)
sandw3<-(Mtrafo)%*%(breadi)%*%(meat3)%*%(breadi)%*%t(Mtrafo)
sandwich3<-round(sqrt(diag(sandw3)),5)
var.sand3<-c(sandwich3[1:numcov],sandwich3[t4+numcov],sandwich3[t2+numcov],sandwich3[t1+numcov])
#print(c(vsta,vnum,nall))
sum(mydata$time==tau)
#
result1 <- c(para,var.bread,var.sand,var.sand3)
para <- result1[1:5]
varbread <- result1[6:10]
varsand <- result1[11:15]
varsand3 <- result1[16:20]
#################################################################################
return(data.frame(cbind(para,varbread,varsand,varsand3)))
}
#wNPMLE.BC(mydata,1,0.95)
#install.packages("roxygen2")
#library(roxygen2)
#devtools::load_all()
#devtools::document()
#roxygen2::roxygenise()
#rm(list = c("wNPMLE.BC"))
#devtools::check()
#rm(list = c("wNPMLE.BC"))
wNPMLE.BC(mydata,1,0.95)
getwd()
